{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1134f74d",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eed8581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re       \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0814fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (4.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (0.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8987a78c",
   "metadata": {},
   "source": [
    "# Reading in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "35c00b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a collection of her photos -- about 80 pages worth with a nice section of paintings by Olivia.If you're looking for heavy literary content, this isn't the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after reading Philip Nel's book I changed my mind--that's a good testimonial to the power of Rel's writing and thinking. Rel plays Dr. Seuss the ultimate compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"the child is father to the man,\" then Dr. Seuss (Theodor Seuss Geisel) is the most influential author, poet, and artist of modern times. For me, a dadd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;Dr. Seuss,&amp;quot; was one of the most influential writers and artists of the 20th century.In 1959, Rudolf Flesch wrote, &amp;quot;A hundred years from now, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title  Price         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
       "\n",
       "                          profileName review/helpfulness  review/score  \\\n",
       "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
       "1                       Kevin Killian              10/10           5.0   \n",
       "2                        John Granger              10/11           5.0   \n",
       "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
       "\n",
       "   review/time                                   review/summary  \\\n",
       "0    940636800           Nice collection of Julie Strain images   \n",
       "1   1095724800                                Really Enjoyed It   \n",
       "2   1078790400  Essential for every personal and Public Library   \n",
       "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
       "\n",
       "                                                                                                                                                                                               review/text  \n",
       "0  This is only for Julie Strain fans. It's a collection of her photos -- about 80 pages worth with a nice section of paintings by Olivia.If you're looking for heavy literary content, this isn't the ...  \n",
       "1  I don't care much for Dr. Seuss but after reading Philip Nel's book I changed my mind--that's a good testimonial to the power of Rel's writing and thinking. Rel plays Dr. Seuss the ultimate compli...  \n",
       "2  If people become the books they read and if \"the child is father to the man,\" then Dr. Seuss (Theodor Seuss Geisel) is the most influential author, poet, and artist of modern times. For me, a dadd...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;Dr. Seuss,&quot; was one of the most influential writers and artists of the 20th century.In 1959, Rudolf Flesch wrote, &quot;A hundred years from now, ...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Books_rating.csv')\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "82f919b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df_1 = df.copy()\n",
    "df_2 = df_1[[\"review/text\",\"review/summary\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48b64fe2",
   "metadata": {},
   "source": [
    "## Data info and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3d2e4b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000000 entries, 0 to 2999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Dtype \n",
      "---  ------          ----- \n",
      " 0   review/text     object\n",
      " 1   review/summary  object\n",
      "dtypes: object(2)\n",
      "memory usage: 45.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ec9d7e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review/text</th>\n",
       "      <th>review/summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2999992</td>\n",
       "      <td>2999962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2062648</td>\n",
       "      <td>1592315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>digital books are perfect and easy to use! They take up no space on the bookshelf and are always with you!!!</td>\n",
       "      <td>Great Book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>322</td>\n",
       "      <td>6848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         review/text  \\\n",
       "count                                                                                                        2999992   \n",
       "unique                                                                                                       2062648   \n",
       "top     digital books are perfect and easy to use! They take up no space on the bookshelf and are always with you!!!   \n",
       "freq                                                                                                             322   \n",
       "\n",
       "       review/summary  \n",
       "count         2999962  \n",
       "unique        1592315  \n",
       "top        Great Book  \n",
       "freq             6848  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6661e3e",
   "metadata": {},
   "source": [
    "# Renaming the two necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "763fcbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is only for Julie Strain fans. It's a collection of her photos -- about 80 pages worth with a nice section of paintings by Olivia.If you're looking for heavy literary content, this isn't the ...</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't care much for Dr. Seuss but after reading Philip Nel's book I changed my mind--that's a good testimonial to the power of Rel's writing and thinking. Rel plays Dr. Seuss the ultimate compli...</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If people become the books they read and if \"the child is father to the man,\" then Dr. Seuss (Theodor Seuss Geisel) is the most influential author, poet, and artist of modern times. For me, a dadd...</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;Dr. Seuss,&amp;quot; was one of the most influential writers and artists of the 20th century.In 1959, Rudolf Flesch wrote, &amp;quot;A hundred years from now, ...</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is basically an academic overview of Seuss poetry, art, cartoons, and the problems with the commercialization of the Seuss name and works after his death....</td>\n",
       "      <td>Good academic overview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>This is an extremely difficult book to digest, and it is not for casual readers. However, Collingwood's ideas on a meeting of minds between past and present is absolutely fascinating and gets to t...</td>\n",
       "      <td>Difficult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>This is pretty interesting. Collingwood seems like on of the first historians to really utilize ideas from evolutionary theory and modern psychology in his overall method. He manages to create a v...</td>\n",
       "      <td>Quite good and ahead of its time occasionally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>This is a good book but very esoteric. \"What is History?\" by E.H. Carr is an easier selection for the causal reader or someone beginning to study historiography.</td>\n",
       "      <td>Easier reads of those not well versed in historiography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>My daughter, a freshman at Indiana University, e-mailed me a list of the books she needed. This was on it... I ordered it, paid for it, and had it shipped directly to her. It arrived sooner than e...</td>\n",
       "      <td>Yes, it is cheaper than the University Bookstore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>The guy has a few good ideas but, reader, beware; this is the transciption of several different lectures over several years. I use the term &amp;quot;different&amp;quot; loosely because each appears to be...</td>\n",
       "      <td>Collingwood's ideas sink in a quagmire or verbiage.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                            text  \\\n",
       "0        This is only for Julie Strain fans. It's a collection of her photos -- about 80 pages worth with a nice section of paintings by Olivia.If you're looking for heavy literary content, this isn't the ...   \n",
       "1        I don't care much for Dr. Seuss but after reading Philip Nel's book I changed my mind--that's a good testimonial to the power of Rel's writing and thinking. Rel plays Dr. Seuss the ultimate compli...   \n",
       "2        If people become the books they read and if \"the child is father to the man,\" then Dr. Seuss (Theodor Seuss Geisel) is the most influential author, poet, and artist of modern times. For me, a dadd...   \n",
       "3        Theodore Seuss Geisel (1904-1991), aka &quot;Dr. Seuss,&quot; was one of the most influential writers and artists of the 20th century.In 1959, Rudolf Flesch wrote, &quot;A hundred years from now, ...   \n",
       "4        Philip Nel - Dr. Seuss: American IconThis is basically an academic overview of Seuss poetry, art, cartoons, and the problems with the commercialization of the Seuss name and works after his death....   \n",
       "...                                                                                                                                                                                                          ...   \n",
       "2999995  This is an extremely difficult book to digest, and it is not for casual readers. However, Collingwood's ideas on a meeting of minds between past and present is absolutely fascinating and gets to t...   \n",
       "2999996  This is pretty interesting. Collingwood seems like on of the first historians to really utilize ideas from evolutionary theory and modern psychology in his overall method. He manages to create a v...   \n",
       "2999997                                        This is a good book but very esoteric. \"What is History?\" by E.H. Carr is an easier selection for the causal reader or someone beginning to study historiography.   \n",
       "2999998  My daughter, a freshman at Indiana University, e-mailed me a list of the books she needed. This was on it... I ordered it, paid for it, and had it shipped directly to her. It arrived sooner than e...   \n",
       "2999999  The guy has a few good ideas but, reader, beware; this is the transciption of several different lectures over several years. I use the term &quot;different&quot; loosely because each appears to be...   \n",
       "\n",
       "                                                         summary  \n",
       "0                         Nice collection of Julie Strain images  \n",
       "1                                              Really Enjoyed It  \n",
       "2                Essential for every personal and Public Library  \n",
       "3                Phlip Nel gives silly Seuss a serious treatment  \n",
       "4                                         Good academic overview  \n",
       "...                                                          ...  \n",
       "2999995                                                Difficult  \n",
       "2999996            Quite good and ahead of its time occasionally  \n",
       "2999997  Easier reads of those not well versed in historiography  \n",
       "2999998         Yes, it is cheaper than the University Bookstore  \n",
       "2999999      Collingwood's ideas sink in a quagmire or verbiage.  \n",
       "\n",
       "[3000000 rows x 2 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.rename(columns={\"review/text\":\"text\", \"review/summary\":\"summary\"}, inplace=True)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f7758e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2.dropna(how='any', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3efd6d2",
   "metadata": {},
   "source": [
    "# Limiting the rows of the data to 100000\n",
    "\n",
    "### This eradicates longer runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "20865ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2[:100000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60a41a53",
   "metadata": {},
   "source": [
    "# Installing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4fb6e8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (2.10.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: nltk in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: xxhash in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (0.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.9.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\oyeni\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets nltk rouge_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f27e62f",
   "metadata": {},
   "source": [
    "# Rouge score calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "278d7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "def calc_rouge_scores(candidates, references):\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    result = {key: round(value.mid.fmeasure * 100, 1) for key, value in result.items()}\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec64bdbc",
   "metadata": {},
   "source": [
    "# creating a BASELINE Model and calculating the Rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc587694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 1 senctences: Scores {'rouge1': 10.8, 'rouge2': 3.1, 'rougeL': 9.9, 'rougeLsum': 9.9}\n",
      "First 2 senctences: Scores {'rouge1': 9.0, 'rouge2': 2.4, 'rougeL': 8.0, 'rougeLsum': 8.0}\n",
      "First 3 senctences: Scores {'rouge1': 7.7, 'rouge2': 2.0, 'rougeL': 6.7, 'rougeLsum': 6.7}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ref_summaries = list(df_3['summary'])\n",
    "\n",
    "for i in range (3):\n",
    "    candidate_summaries = list(df_3['text'].apply(lambda x: ' '.join(re.split(r'(?<=[.:;])\\s', x)[:i+1])))\n",
    "    print(f\"First {i+1} senctences: Scores {calc_rouge_scores(candidate_summaries, ref_summaries)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "475f0ffe",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "###     - Removing extra white spaces\n",
    "###     - Expand contractions\n",
    "###     - Remove special case characters\n",
    "###     - Lowercasing all letters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a9ead0c",
   "metadata": {},
   "source": [
    "### Dictionary to be used for expanding contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f4be97ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "040a5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                  #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "cleaned_text = []\n",
    "for t in df_3['text']:\n",
    "    cleaned_text.append(text_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1b44d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for summary\n",
    "def summary_cleaner(text):\n",
    "    newString = re.sub('\"','', text)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    newString = newString.lower()\n",
    "    tokens=newString.split()\n",
    "    newString=''\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            newString=newString+i+' '  \n",
    "    return newString\n",
    "\n",
    "#Call the above function\n",
    "cleaned_summary = []\n",
    "for t in df_3['summary']:\n",
    "    cleaned_summary.append(summary_cleaner(t))\n",
    "\n",
    "df_3['cleaned_text']=cleaned_text\n",
    "df_3['cleaned_summary']=cleaned_summary\n",
    "df_3['cleaned_summary'].replace('', np.nan, inplace=True)\n",
    "df_3.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78b1b799",
   "metadata": {},
   "source": [
    "### Adding tokens to the start and end of the summary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "30356cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['cleaned_summary'] = df_3['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "70f8d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: julie strain fans collection photos pages worth nice section paintings olivia looking heavy literary content place find pages text everything else photos bottom line want one book six foot one probably better choice however like julie like like julie wrong one either\n",
      "Summary: _START_ nice collection of julie strain images  _END_\n",
      "\n",
      "\n",
      "Review: care much seuss reading philip nel book changed mind good testimonial power rel writing thinking rel plays seuss ultimate compliment treating serious poet well one century interesting visual artists reading book decided trip mandeville collections library university california san diego order could visit incredible seuss geisel holdings almost much take like william butler yeats seuss led career constantly shifted metamoprhized meet new historical political cirsumstances seems leftist conservative different junctures career politics art nel shows cartoonist fabled magazine like andy warhol served time slaving business service amusing broadening minds children nel hesitate administer sound spanking seuss industry since death seen fit license kinds awful products including recent cat hat film mike myers cat astrophe book great especially recommend work picture editor given bounty good illustrations\n",
      "Summary: _START_ really enjoyed it  _END_\n",
      "\n",
      "\n",
      "Review: people become books read child father man seuss influential author poet artist modern times daddy large family learned read seuss memorized many books via repeated readings young children prof nel brilliant american icon long awaited treat last serious treatment remarkable genius engaging read filled remarkable insights especially enjoyed prof nel discussions disneyfication seuss nel links failings american copyright law sides seuss sides new political genesis secular morality wwii cartoon work magazine chapters geisel poetry artwork link nel makes seuss historical avant guarde alone make book must buy parents serious readers mention public libraries readers nel books find engaging writing style makes book fun read imparting mountain information important ideas simply best comprehensive book yet written work seuss geisel certainly standard many years come thank prof nel wherever reader grew good doctor growing years later book written encyclopeadic knowledge children literature media genre scanning verse cubist painting explains power limits popularity seuss phenomenon\n",
      "Summary: _START_ essential for every personal and public library  _END_\n",
      "\n",
      "\n",
      "Review: theodore seuss geisel aka quot seuss quot one influential writers artists century rudolf flesch wrote quot hundred years children parents still eagerly read books fellow called ted geisel popularly known seuss quot flesch conservative prediction century today seuss still read many authors today bestseller lists forgotten published centenary geisel birth seuss american icon analyzes six key aspects seuss career poetry politics art biography marketing influence six insightful chapters philip nel assistant professor english kansas state university discusses quot laureate nonsense quot quot seuss adolf hitler quot quot doc smock quot quot fingers quot quot disneyfication seuss quot quot cat hat president quot nel gives short shrift geisel childhood family background indeed biography general preferring focus seuss writing art first book think saw mulberry street last book places seuss breakthrough year published two books often identified cat hat grinch stole christmas classic works seussian canon horton hears yertle turtle green eggs ham sneeches lorax butter battle book favorite work among books authored cat hat taught children read many books clear powerful moral seuss horror heavy handed preaching sought teach ignite imagination lifelong opponent smug self righteous bourgeois moralism quot seuss contrarian quot writes nel quot enjoyed challenging people reconsider assumptions rebellious imagination dispositional distaste rules regulations quot work quot rational insanity quot exhibited quot joyous anarchy quot quot lifelong thrill misbehaving quot better subtitle nel work would american icon iconoclast nel tells seuss early years advertising artist agitprop cartoonist book however biography serious study genres literary art criticism readers want biographical information nel recommends seuss geisel judith morgan neil morgan describes quot definitive biography single best secondary source seuss discussion seuss life work must begin book quot seuss american icon includes pages notes index comprehensive annotated seuss bibliography ever assembled one learns lot book author lucid style makes enlightening work fun read philip nel author rowling harry potter novels reader guide avant garde american postmodernity roy perry nolensville tennessee advertising copywriter nashville publishing house\n",
      "Summary: _START_ phlip nel gives silly seuss serious treatment  _END_\n",
      "\n",
      "\n",
      "Review: philip nel seuss american iconthis basically academic overview seuss poetry art cartoons problems commercialization seuss name works death real extent biography seeking move academic book leans dry side assumes reader fairly good knowledge children literature century cartoons book begin seuss experience read children interested writing style art style interested deconstruction recent rush cash seuss hollywood advertisers think nel wants come based seuss background projects approved lifetime tough argument make end though nel point maybe movies tie ins crass book well researched lots neat tidbits gleamed early cartoons seuss magazine occasionally shockingly racist makes little human puts latter works like lorax new light education may enjoy background fans seuss enjoy exhaustive bibliography seuss many many works also good list works man\n",
      "Summary: _START_ good academic overview  _END_\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Review:\",df_3['cleaned_text'][i])\n",
    "    print(\"Summary:\",df_3['cleaned_summary'][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2a194e0",
   "metadata": {},
   "source": [
    "##### Plotting the distribution sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e446f3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in df_3['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in df_3['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c18b14ac",
   "metadata": {},
   "source": [
    "# Getting the percentile values of the word count of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fc362cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is 1\n",
      "10 percentile value is 27\n",
      "20 percentile value is 41\n",
      "30 percentile value is 57\n",
      "40 percentile value is 74\n",
      "50 percentile value is 95\n",
      "60 percentile value is 121\n",
      "70 percentile value is 157\n",
      "80 percentile value is 213\n",
      "90 percentile value is 323\n",
      "100 percentile value is  4928\n",
      " FROM 90 TO 100\n",
      "90 percentile value is 323\n",
      "91 percentile value is 341\n",
      "92 percentile value is 363\n",
      "93 percentile value is 389\n",
      "94 percentile value is 419\n",
      "95 percentile value is 455\n",
      "96 percentile value is 499\n",
      "97 percentile value is 554\n",
      "98 percentile value is 640\n",
      "99 percentile value is 793\n",
      "100 percentile value is  4928\n"
     ]
    }
   ],
   "source": [
    "df_3['word count text'] = df_3['text'].apply(lambda x : len(str(x).split()))\n",
    "for i in range(0,100,10):\n",
    "    var = df_3['word count text'].values\n",
    "    var = np.sort(var, axis=None)\n",
    "    print('{} percentile value is {}'.format(i, var[int(len(var)*(float(i)/100))]))\n",
    "print('100 percentile value is ', var[-1])\n",
    "\n",
    "\n",
    "\n",
    "print(' FROM 90 TO 100')\n",
    "\n",
    "\n",
    "for i in range(90,100):\n",
    "    var = df_3['word count text'].values\n",
    "    var = np.sort(var, axis=None)\n",
    "    print('{} percentile value is {}'.format(i, var[int(len(var)*(float(i)/100))]))\n",
    "print('100 percentile value is ', var[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5b728d6",
   "metadata": {},
   "source": [
    "### For summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6432e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is 1\n",
      "10 percentile value is 2\n",
      "20 percentile value is 2\n",
      "30 percentile value is 3\n",
      "40 percentile value is 4\n",
      "50 percentile value is 4\n",
      "60 percentile value is 5\n",
      "70 percentile value is 6\n",
      "80 percentile value is 7\n",
      "90 percentile value is 9\n",
      "100 percentile value is  26\n",
      " FROM 90 TO 100\n",
      "90 percentile value is 9\n",
      "91 percentile value is 9\n",
      "92 percentile value is 9\n",
      "93 percentile value is 9\n",
      "94 percentile value is 10\n",
      "95 percentile value is 10\n",
      "96 percentile value is 10\n",
      "97 percentile value is 11\n",
      "98 percentile value is 12\n",
      "99 percentile value is 13\n",
      "100 percentile value is  26\n"
     ]
    }
   ],
   "source": [
    "df_3['word count summary'] = df_3['summary'].apply(lambda x : len(str(x).split()))\n",
    "for i in range(0,100,10):\n",
    "    var = df_3['word count summary'].values\n",
    "    var = np.sort(var, axis=None)\n",
    "    print('{} percentile value is {}'.format(i, var[int(len(var)*(float(i)/100))]))\n",
    "print('100 percentile value is ', var[-1])\n",
    "\n",
    "\n",
    "\n",
    "print(' FROM 90 TO 100')\n",
    "\n",
    "\n",
    "for i in range(90,100):\n",
    "    var = df_3['word count summary'].values\n",
    "    var = np.sort(var, axis=None)\n",
    "    print('{} percentile value is {}'.format(i, var[int(len(var)*(float(i)/100))]))\n",
    "print('100 percentile value is ', var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "19f35640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the maximum for both text and summary\n",
    "\n",
    "max_count_text = 80\n",
    "max_count_summary = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "92310e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset with train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_3['text'], df_3['summary'], test_size=0.3, random_state=23)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7aecdb67",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "#### _Changing_ and _Passing_ the text values into a more understandable format for the model\n",
    "#### Tokenizing both _text_ and _summary_ columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6bbf15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text\n",
    "#prepare a tokenizer for text on training data\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_train    =   x_tokenizer.texts_to_sequences(x_train) \n",
    "x_test   =   x_tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_train    =   pad_sequences(x_train,  maxlen=max_count_text, padding='post') \n",
    "x_test   =   pad_sequences(x_test, maxlen=max_count_text, padding='post')\n",
    "\n",
    "x_voc_size   =  len(x_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4c222360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#preparing a tokenizer for summary on training data \n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "#convert summary sequences into integer sequences\n",
    "y_train    =   y_tokenizer.texts_to_sequences(y_train) \n",
    "y_test   =   y_tokenizer.texts_to_sequences(y_test) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_train    =   pad_sequences(y_train, maxlen=max_count_summary, padding='post')\n",
    "y_test   =   pad_sequences(y_test, maxlen=max_count_summary, padding='post')\n",
    "\n",
    "y_voc_size  =   len(y_tokenizer.word_index) +1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba741633",
   "metadata": {},
   "source": [
    "### BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7aab6f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 80)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 80, 500)      63956500    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 80, 500),    2002000     ['embedding[0][0]']              \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 80, 500),    2002000     ['lstm[0][0]']                   \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 500)    10602500    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 80, 500),    2002000     ['lstm_1[0][0]']                 \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 500),  2002000     ['embedding_1[0][0]',            \n",
      "                                 (None, 500),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 500)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 21205)  10623705   ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 93,190,705\n",
      "Trainable params: 93,190,705\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session() \n",
    "latent_dim = 500 \n",
    "\n",
    "# Encoder \n",
    "encoder_inputs = Input(shape=(max_count_text,)) \n",
    "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Set up the decoder. \n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "# Attention Layer\n",
    "# Attention layer attn_layer = AttentionLayer(name='attention_layer') \n",
    "# attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "# decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_outputs) \n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54e8f950",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "### Using sparse categorical cross-entropy as the loss function since it converts the integer sequence to a one-hot vector on the fly.\n",
    "### This preserves/ solves memory issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f8798b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "507f9acf",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "\n",
    "###  It is used to stop training the neural network at the right time by monitoring a user-specified metric.\n",
    "###  Monitoring the validation loss (val_loss). The model will stop training once the validation loss increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c53b152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f298031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3189825",
   "metadata": {},
   "source": [
    "### Diagnostic Plot\n",
    "\n",
    "#### To understand the behaviour of the model over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8e61f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot \n",
    "# pyplot.plot(history.history['loss'], label='train') \n",
    "# pyplot.plot(history.history['val_loss'], label='test') \n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57e0246c",
   "metadata": {},
   "source": [
    "### Building dictionary to convert the index to word for target and source vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9cbb279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word \n",
    "reverse_source_word_index=x_tokenizer.index_word \n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98b1c84b",
   "metadata": {},
   "source": [
    "### Setting up inference for encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "db449698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_count_text,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# #attention inference\n",
    "# attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f5844b4",
   "metadata": {},
   "source": [
    "#### Decode Sequence Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6a802356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_count_summary-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b77e91c1",
   "metadata": {},
   "source": [
    "#### Defining the functions to convert an integer sequence to a word sequence for summary as well as the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d45fc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8df299b8",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "66823cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: i love edgar allan poe i enjoyed reading him in school and enjoy reading him today i love having this on my kindle \n",
      "Original summary: i love edgar \n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicted summary:  horeseman acton orrigina pawn copies copies copies frank's mankind\n",
      "\n",
      "\n",
      "Review: for a bookclub there were so many different abridged versions that i finally gave up and bought the unabridged i am so glad i did my husband and i both read and loved this book it's a great translation and i would definitely recommend the unabridged version it was interesting in my bookclub to hear all of the different plot lines left out of the various abridged versions some of them were pretty pivotal i'd stick with this great version \n",
      "Original summary: loved this book \n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Predicted summary:  dogs nerd 1500 pitiable capitol horrid horrid infrequent infrequent\n",
      "\n",
      "\n",
      "Review: a great book to read i enjoy reading about the mennonites and there ways of living reading helps keep the mind active and showes that there are different ways to proceed in life \n",
      "Original summary: amanda \n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicted summary:  horeseman acton orrigina pawn copies copies copies frank's mankind\n",
      "\n",
      "\n",
      "Review: the truth about java itself for example he comes right out on page 49 and states quot static is a crummy name quot how true he then offers alternative names that better describe the situation most books on java are extremely abstract and abstruse this book isn't it's great the cd alone is worth the purchase price it is full of intriguing examples and applets this should be required reading i simply can't say enough good things about this book \n",
      "Original summary: can't say enough good things about this book it's great \n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  grudge incredibily acatually sequels pilgrim's dialectic esp renegade said\n",
      "\n",
      "\n",
      "Review: havens has caught the essence of what it takes to win a war the story of those non commissioned officers who and labored in the rear echelon to see that battles were won and who provided the support and know how to see that the front line troops received the help they needed has finally been told these unsung heroes are finally getting the recognition they deserve my hat is off to the writer who was one of these people \n",
      "Original summary: a story that should have been told years ago \n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  could've whitebedreamin talkies griffiths meticulous stare revisionism ashgabat caesar\n",
      "\n",
      "\n",
      "Review: is correct in human evolutionary history even thoughs who critisize his quaint use of terms do so from a perspective elevated by his work i found his writing prescient in light of the displayed in fossils if you need a context then read janet browne's seminal two volume darwin biography if you need adventure and a darwinian primer then read voyage of the beagle but don't stop reading darwin till you've read this book the origin is incomplete without it \n",
      "Original summary: a great read but not for everyone \n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  dogs nerd 1500 pitiable capitol horrid hits t'ai awesomeness\n",
      "\n",
      "\n",
      "Review: i bought this book before i read some of the detailed reviews praising the story for children and teens i decided to read it anyway and found the story quite enjoyable the history interesting and the characters well developed can recommend for all ages \n",
      "Original summary: thought i bought a children's book \n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  horeseman acton orrigina pawn copies copies copies frank's mankind\n",
      "\n",
      "\n",
      "Review: i grew up in the bethesda chevy chase area but was slightly younger that holland her story reminded me of my of my own teenage angst well written \n",
      "Original summary: memoir \n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  horeseman acton orrigina pawn copies copies copies frank's mankind\n",
      "\n",
      "\n",
      "Review: then you will apreciate this book but it did tend to ramble for those of us who are used to auel's style it was not a huge surprise at times i felt as though i was re reading all the books over again i felt however that it was really satisfying to read overall and i recomend it to all who have enjoyed the series \n",
      "Original summary: if you have read the other four \n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  war there's goofy lj drunkard 000 futureworld futureworld countering\n",
      "\n",
      "\n",
      "Review: i loved these books they were the greatest of all time i felt it when eragon was hurt i experienced his wonder at having his own dragon these books were amazing write more please \n",
      "Original summary: no sleep \n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  horeseman acton orrigina pawn copies copies copies frank's mankind\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(\"Review:\",seq2text(x_test[i]))\n",
    "  print(\"Original summary:\",seq2summary(y_test[i]))\n",
    "  print(\"Predicted summary:\",decode_sequence(x_test[i].reshape(1,max_count_text)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101cb4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
